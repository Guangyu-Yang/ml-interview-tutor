# ML Interview Study Tracker

**Last Updated**: 2026-02-17

**Target Interview Date**: [Your interview date]

**Overall Interview Readiness**: 54%

---

## Quick Stats

| Domain | Topics Covered | Total Topics | Status |
|--------|---------------|--------------|--------|
| A. ML Fundamentals (20%) | 3 | 8 | üü° In Progress |
| B. Classical ML (15%) | 0 | 7 | üî¥ Not Started |
| C. Deep Learning & RL (25%) | 6 (+2 in progress) | 11 | üü° In Progress |
| D. NLP & Multi-Modal (12%) | 1 | 10 | üü° In Progress |
| E. ML System Design (18%) | 8 | 8 | üü¢ Interview Ready |
| F. Practical ML (10%) | 3 | 6 | üü° In Progress |

**Status Legend**: üî¥ Not Started | üü° In Progress | üü¢ Interview Ready

---

## Study Priority (Based on Weights)

1. üî• **Deep Learning & RL (25%)** - Transformers, attention, CNNs, RNNs, RL, RLHF ‚Äî GOOD PROGRESS
2. üî• **ML Fundamentals (20%)** - Gradient descent, bias-variance, regularization
3. ‚úÖ **ML System Design (18%)** - Pipelines, serving, A/B testing ‚Äî COMPLETE (8/8)
4. üìå **Classical ML (15%)** - Trees, SVM, clustering
5. üìã **NLP & Multi-Modal (12%)** - Embeddings, BERT, ViT, CLIP, multi-modal LLMs
6. üìã **Practical ML (10%)** - Debugging, imbalanced data ‚Äî STARTED

---

## Topics Mastered

### A. ML Fundamentals
| Topic | Date Mastered | Confidence | Key Points |
|-------|---------------|------------|------------|
| **A.8 Evaluation Metrics - AUC-ROC** | 2026-02-02 | Medium-High | ‚Ä¢ Measures ranking ability across all thresholds<br>‚Ä¢ AUC = P(random positive ranks higher than random negative)<br>‚Ä¢ Threshold-independent, handles imbalanced data<br>‚Ä¢ AUC=0.5 (random), AUC=1.0 (perfect)<br>‚Ä¢ Use AUC for flexible thresholds; Precision@k for fixed top-k<br>‚Ä¢ ROC axes: x=FPR, y=TPR |
| **A.3 Gradient Descent & Optimization - Logistic Regression** | 2026-02-02 | High | ‚Ä¢ Derived complete gradient from first principles<br>‚Ä¢ Chain rule: ‚àÇL/‚àÇw = (‚àÇL/‚àÇ≈∑)(‚àÇ≈∑/‚àÇz)(‚àÇz/‚àÇw)<br>‚Ä¢ Beautiful simplification: ‚àÇL/‚àÇz = ≈∑ - y<br>‚Ä¢ Complete gradient: ‚àÇL/‚àÇw = (≈∑ - y)x + Œªw<br>‚Ä¢ L2 regularization adds Œªw term (weight decay)<br>‚Ä¢ Can derive on whiteboard for interviews |
| **A.3 Optimizers - SGD/Momentum/RMSProp/Adam/AdamW** | 2026-02-10 | Medium-High | ‚Ä¢ SGD: w = w - lr*dw (baseline)<br>‚Ä¢ Momentum: accumulates gradient direction, cancels oscillation<br>‚Ä¢ RMSProp: per-parameter adaptive LR via running avg of squared gradients<br>‚Ä¢ Adam = Momentum + RMSProp + bias correction (mÃÇ=m/(1-Œ≤‚ÇÅ·µó))<br>‚Ä¢ Œ≤‚ÇÇ=0.999 needs correction longer than Œ≤‚ÇÅ=0.9<br>‚Ä¢ AdamW: decouples weight decay from adaptive scaling (uniform regularization)<br>‚Ä¢ Adam+L2 distorts regularization; AdamW applies Œªw directly to weights |

### B. Classical ML
| Topic | Date Mastered | Confidence | Key Points |
|-------|---------------|------------|------------|
| ‚Äî | ‚Äî | ‚Äî | ‚Äî |

### C. Deep Learning & RL
| Topic | Date Mastered | Confidence | Key Points |
|-------|---------------|------------|------------|
| **C.21 Transformers & Self-Attention** | 2026-02-02 | High | ‚Ä¢ Self-attention solves RNN bottlenecks (parallel + direct connections)<br>‚Ä¢ O(n¬≤) complexity trade-off for long sequences<br>‚Ä¢ Q, K, V mechanism: similarity-weighted information retrieval<br>‚Ä¢ Positional encodings needed (RoPE, sinusoidal, learned)<br>‚Ä¢ BERT (encoder, bidirectional) vs GPT (decoder, causal)<br>‚Ä¢ Can explain architecture choices for different tasks |
| **C.21 Multi-Head Attention** | 2026-02-03 | High | ‚Ä¢ Different heads learn different relationship types (syntactic, semantic, positional)<br>‚Ä¢ Examples: subject-verb, pronoun resolution, induction heads<br>‚Ä¢ d_k = d_model / num_heads (e.g., 512/8 = 64)<br>‚Ä¢ W^O projection fuses knowledge across heads<br>‚Ä¢ More heads needed for complex sequences (more patterns to capture) |
| **C.16 Backpropagation** | 2026-02-03 | High | ‚Ä¢ Chain rule applied layer-by-layer: ‚àÇL/‚àÇW‚ÇÅ = (≈∑-y) √ó W‚ÇÇ √ó ReLU'(z‚ÇÅ) √ó x<br>‚Ä¢ Error signal (Œ¥) computed once per layer, reused for all gradients<br>‚Ä¢ ‚àÇL/‚àÇW = Œ¥ √ó (input to that layer)<br>‚Ä¢ Vanishing gradients: small weights multiply ‚Üí tiny gradients<br>‚Ä¢ Exploding gradients: large weights multiply ‚Üí huge gradients<br>‚Ä¢ Solutions: ReLU, residual connections, gradient clipping |
| **C.17 Softmax & Cross-Entropy Gradient** | 2026-02-03 | High | ‚Ä¢ Softmax: ≈∑·µ¢ = e^z·µ¢ / Œ£e^z‚±º<br>‚Ä¢ Cross-entropy: L = -Œ£ y·µ¢ log(≈∑·µ¢)<br>‚Ä¢ ‚àÇ≈∑·µ¢/‚àÇz·µ¢ = ≈∑·µ¢(1-≈∑·µ¢), ‚àÇ≈∑·µ¢/‚àÇz‚±º = -≈∑·µ¢¬∑≈∑‚±º (i‚â†j)<br>‚Ä¢ Final gradient: ‚àÇL/‚àÇz‚±º = ≈∑‚±º - y‚±º (same as binary!)<br>‚Ä¢ One-hot vector sums to 1 ‚Üí enables simplification<br>‚Ä¢ Practical benefits: numerical stability, simple implementation |
| **C.18 BatchNorm vs LayerNorm** *(in progress)* | 2026-02-09 | Medium | ‚Ä¢ BatchNorm: across batch dim; LayerNorm: across feature dim<br>‚Ä¢ LayerNorm for NLP: no batch dependency, same at train/test<br>‚Ä¢ Padding pollution issue with BatchNorm on variable-length sequences<br>‚Ä¢ RMSNorm: removes mean centering + beta, ~10-15% faster<br>‚Ä¢ ‚ö†Ô∏è Review needed: BatchNorm placement (before activation), RMSNorm details |
| **C.23 Training Techniques - Unified SFT/Distillation/RL Framework** | 2026-02-10 | Medium-High | ‚Ä¢ 2x2 framework: (on/off-policy) √ó (sparse/dense signal)<br>‚Ä¢ All four share gradient: weight √ó ‚àálog œÄ_Œ∏(y\|x)<br>‚Ä¢ SFT weight=ùüô(y=y*), RL weight=r(x,y), Distillation weight=œÄ_teacher<br>‚Ä¢ On vs off-policy: who generates data (student vs fixed dataset)<br>‚Ä¢ Sparse vs dense: one-hot/reward vs full teacher distribution<br>‚Ä¢ IS unification: off-policy methods get œÄ_data/œÄ_Œ∏ correction<br>‚Ä¢ SFT = sparse RL with indicator reward<br>‚Ä¢ RL can surpass teacher (no ceiling); distillation bounded by teacher |
| **C.23 Knowledge Distillation (Math)** *(in progress)* | 2026-02-17 | Medium | ‚Ä¢ Dark knowledge: soft probabilities encode inter-class relationships<br>‚Ä¢ Temperature T softens distributions: p_i = e^(z_i/T) / Œ£e^(z_j/T)<br>‚Ä¢ KL divergence loss (KL=0 when distributions match)<br>‚Ä¢ Combined loss: L = Œ±¬∑T¬≤¬∑KL(teacher‚Äñstudent) + (1-Œ±)¬∑CE(y, student)<br>‚Ä¢ T¬≤ scaling compensates 1/T¬≤ gradient reduction from temperature<br>‚Ä¢ Œ± tradeoff: Œ±=1 pure distillation (bounded by teacher), Œ±=0 normal training<br>‚Ä¢ ‚ö†Ô∏è Needs interview rehearsal next session |

### D. NLP & Multi-Modal
| Topic | Date Mastered | Confidence | Key Points |
|-------|---------------|------------|------------|
| **D.31 Contrastive Learning (InfoNCE)** | 2026-02-10 | High | ‚Ä¢ InfoNCE = cross-entropy over positive + in-batch negatives<br>‚Ä¢ Temperature œÑ controls softmax sharpness (small=peaky, large=smooth)<br>‚Ä¢ Larger batch = more hard negatives = finer-grained representations<br>‚Ä¢ Projection head buffers encoder from info loss (discard after training)<br>‚Ä¢ More important with aggressive augmentations<br>‚Ä¢ InfoNCE preferred over triplet loss: richer gradients, no hard-negative mining needed |

### E. ML System Design
| Topic | Date Mastered | Confidence | Key Points |
|-------|---------------|------------|------------|
| **E.34 End-to-End ML Pipeline Design** | 2026-02-03 | Medium-High | ‚Ä¢ Start with business metrics, not models<br>‚Ä¢ Pipeline: Requirements ‚Üí Data ‚Üí Features ‚Üí Model ‚Üí Serving ‚Üí Evaluation<br>‚Ä¢ Baseline first (heuristics/logistic regression), iterate to complexity<br>‚Ä¢ Always frame improvements relative to current system |
| **E.34 Recommendation Systems - ID Embeddings & Cold Start** | 2026-02-10 | High | ‚Ä¢ Simple lookup (small scale) vs hashing/compositional embeddings (large scale)<br>‚Ä¢ Multiple hash functions + sum/concat to reduce collisions<br>‚Ä¢ Sum is lossy but memory efficient; concat preserves info but doubles dim<br>‚Ä¢ Cold start: side features, content similarity, two-tower architecture<br>‚Ä¢ Feedback loop problem: no exposure ‚Üí no data ‚Üí lower ranking ‚Üí spiral<br>‚Ä¢ Exploration strategies: epsilon-greedy, Thompson sampling, position-based |
| **E.34 Listing Recommendation System Design** | 2026-02-10 | Medium-High | ‚Ä¢ Two-sided marketplace: user satisfaction + host fairness + platform revenue<br>‚Ä¢ Retrieval: hard filters ‚Üí BM25 + embedding ANN + collaborative filtering ‚Üí RRF merge<br>‚Ä¢ Ranking: DCN (pointwise, cross features) or Transformer (listwise, inter-item reasoning)<br>‚Ä¢ Transformer masking: encoder (full), causal (order-dependent), prefix (independent)<br>‚Ä¢ Labels: multi-objective weighted scoring w1*P(click) + w2*P(save) + w3*P(book)<br>‚Ä¢ Re-ranking: diversity (MMR), freshness, host fairness, sponsored, geo/price spread |
| **E.35 Feature Engineering & Feature Stores** | 2026-02-03 | Medium-High | ‚Ä¢ Offline (Spark/Hive, batch) vs Online (Flink/Redis, streaming)<br>‚Ä¢ Training-serving skew: same feature computed differently<br>‚Ä¢ Solutions: log-and-wait, unified computation, feature validation<br>‚Ä¢ Some features fundamentally different: percentiles, global aggs, joins, ranks<br>‚Ä¢ Hybrid: slow-changing offline, fast-changing online |
| **E.39 A/B Testing & Experimentation** | 2026-02-03 | Medium-High | ‚Ä¢ ML tests harder: delayed feedback, smaller effects, feedback loops<br>‚Ä¢ Novelty effects, position bias<br>‚Ä¢ Filter bubble: only learn about what you show<br>‚Ä¢ Solutions: exploration (epsilon-greedy, Thompson sampling), IPW<br>‚Ä¢ Feature leakage: temporal availability at prediction time |
| **E.40 Monitoring & Model Degradation** | 2026-02-09 | Medium-High | ‚Ä¢ Three drift types: covariate, label, concept<br>‚Ä¢ Label shift = same pattern, different rate; Concept drift = relationship changes<br>‚Ä¢ 4-layer monitoring: data, model, operational, business<br>‚Ä¢ Operational monitoring segmented by pipeline step<br>‚Ä¢ Alert tiering: P0 (immediate), P1 (hours), P2 (daily)<br>‚Ä¢ Prevention: scheduled retraining, online learning, human-in-the-loop |
| **E.38 Model Serving & Cost Optimization** | 2026-02-17 | Medium-High | ‚Ä¢ Model compression: distillation, quantization, pruning<br>‚Ä¢ MoE: saves compute (8/256 experts) but NOT memory (full model loaded)<br>‚Ä¢ Smart inference: model cascading/routing, speculative decoding<br>‚Ä¢ Infrastructure: caching (exact + semantic), request batching, auto-scaling<br>‚Ä¢ Semantic cache: embed queries ‚Üí ANN search ‚Üí threshold as precision-recall tradeoff<br>‚Ä¢ Quantization math: s=(r_max-r_min)/(2^b-1), z=round(-r_min/s), q=round(r/s)+z<br>‚Ä¢ Symmetric (weights, centered) vs asymmetric (activations, skewed e.g. ReLU)<br>‚Ä¢ PTQ (fast, no retrain) vs QAT (better accuracy, uses STE for backprop through round)<br>‚Ä¢ Cost prioritization: right-size ‚Üí scaling ‚Üí caching ‚Üí cascading ‚Üí compression |

### F. Practical ML
| Topic | Date Mastered | Confidence | Key Points |
|-------|---------------|------------|------------|
| **F.43 Handling Imbalanced Data** | 2026-02-09 | Medium-High | ‚Ä¢ Weighted cross-entropy: weight rare class more, derived gradient (49x larger for minority)<br>‚Ä¢ Focal loss: (1-≈∑)^Œ≥ modulator, Œ≥=0 reduces to weighted CE (RetinaNet, 2017)<br>‚Ä¢ Sampling: oversampling/SMOTE, undersampling, data augmentation<br>‚Ä¢ Threshold tuning as simplest first approach<br>‚Ä¢ Connected to AUC-ROC and AUC-PR for evaluation |
| **F.46 Model Interpretability (SHAP)** | 2026-02-09 | Medium | ‚Ä¢ Shapley values from game theory: average marginal contribution across all orderings<br>‚Ä¢ Exact computation is O(n!) ‚Äî intractable<br>‚Ä¢ Approximations: TreeSHAP O(TLD¬≤), KernelSHAP, DeepSHAP<br>‚Ä¢ Advantages over feature importance: local explanations, directionality, theoretical guarantees<br>‚Ä¢ Guarantees: efficiency (sum to prediction), symmetry, null player |
| **F.42 Debugging Training Issues** | 2026-02-09 | Medium-High | ‚Ä¢ Debugging hierarchy: data ‚Üí sanity checks ‚Üí training mechanics ‚Üí regularization<br>‚Ä¢ Initial loss sanity check: should be log(k) for k classes; LLMs ~10.4 for 32k vocab<br>‚Ä¢ Overfit tiny batch as first diagnostic (validates entire pipeline)<br>‚Ä¢ NaN causes: log(0), exp overflow, 0/0 derivatives, exploding gradients<br>‚Ä¢ Sudden NaN: weight growth, model overconfidence, bad batch, LR schedule<br>‚Ä¢ Overfitting (train‚Üì eval‚Üë) vs underfitting (both high) ‚Äî opposite fixes |

---

## Knowledge Gaps

### üî¥ High Priority (Must fix before interview)
- None identified yet

### üü° Medium Priority (Should review)
- Full end-to-end system design practice (three practices done ‚Äî delivery improving steadily)
- System design: always mention label sources early in summary
- System design: be specific with feature examples (enumerate, don't generalize)
- BatchNorm placement details (before vs after activation ‚Äî original paper says before)
- RMSNorm precise mechanics (removes mean centering + beta, not variance)
- ROC axes confusion (recurring ‚Äî swapped axes again in Session 5, need drilling)
- AUC-PR interpretation nuances (don't compare to 0.5, compare to positive class rate)

### üü¢ Recently Resolved
| Gap | Resolution Date | Notes |
|-----|-----------------|-------|
| Chain rule application in multi-layer networks | 2026-02-03 | Covered in backprop derivation |
| Softmax derivative mechanics | 2026-02-03 | Derived both cases (i=j, i‚â†j) |
| Monitoring & model degradation in production | 2026-02-09 | Built 4-layer monitoring framework, mastered drift types |

---

## Interview Readiness Checklist

### Can You Confidently...

**Fundamentals**
- [x] Derive gradient descent update rules
- [ ] Explain bias-variance tradeoff with examples
- [x] Compare L1 vs L2 regularization (L2 covered in logistic regression)
- [x] Explain AUC-ROC and when to use vs Precision@k
- [x] Compare AUC-ROC vs AUC-PR for imbalanced data
- [ ] Calculate precision, recall, F1 from confusion matrix

**Classical ML**
- [ ] Explain how random forests reduce variance
- [x] Derive logistic regression gradient (with L2 regularization!)
- [ ] Explain SVM margin and kernel trick
- [ ] Describe K-means algorithm and limitations

**Deep Learning & RL**
- [x] Walk through backpropagation step by step
- [x] Explain vanishing gradients and solutions
- [x] Describe attention mechanism and transformers in detail
- [x] Compare BERT vs GPT architectures and use cases
- [x] Explain multi-head attention and W^O projection
- [x] Derive softmax + cross-entropy gradient
- [ ] Compare batch norm vs layer norm (in progress ‚Äî review details)
- [x] Explain unified SFT/Distillation/RL gradient framework
- [ ] Explain RL fundamentals (MDP, Bellman, on/off-policy)
- [ ] Describe policy gradient methods (REINFORCE, PPO, GRPO)
- [ ] Explain RLHF and DPO for LLM alignment

**NLP & Multi-Modal**
- [ ] Explain Word2Vec (skip-gram and CBOW)
- [x] Describe transformer architecture
- [ ] Explain BERT pre-training objectives
- [ ] Explain Vision Transformers (ViT) and patch embeddings
- [x] Explain InfoNCE loss and contrastive learning fundamentals
- [ ] Describe CLIP and text-image contrastive learning
- [ ] Explain multi-modal LLM architectures
- [ ] Describe diffusion models and video generation

**System Design**
- [x] Design an end-to-end ML pipeline
- [x] Explain A/B testing for ML models
- [x] Discuss feature store architecture and tradeoffs
- [x] Identify and prevent feature leakage
- [x] Handle data drift scenarios (covariate, label, concept drift)
- [x] Design a monitoring framework (4-layer: data, model, operational, business)
- [x] Discuss model serving trade-offs and cost optimization

---

## Study Plan

### This Week's Focus
1. [x] A.8 AUC-ROC and evaluation metrics (COMPLETED)
2. [x] A.3 Logistic regression gradient derivation with L2 regularization (COMPLETED)
3. [x] C.21 Transformers & self-attention mechanism (COMPLETED)
4. [x] Multi-head attention - why multiple heads? (COMPLETED)
5. [x] C.16 Backpropagation for simple neural network (COMPLETED)
6. [x] Softmax & cross-entropy gradient (multi-class extension) (COMPLETED)
7. [x] E.34 End-to-end ML pipeline design (COMPLETED)

### Upcoming Topics
- [x] E.40 Monitoring and model degradation (COMPLETED 2026-02-09)
- [x] C.23 Unified SFT/Distillation/RL framework (COMPLETED 2026-02-10)
- [ ] Batch norm vs Layer norm (IN PROGRESS ‚Äî review details needed)
- [ ] C.19 CNNs (convolutions, pooling, architectures)
- [ ] C.20 RNNs, LSTMs, GRUs (vanishing gradients, gating)
- [ ] A.5 Bias-variance tradeoff
- [ ] B.10 Decision trees, random forests, gradient boosting

### Review Scheduled
- [ ] Multi-head attention (reinforce W^O understanding)
- [ ] Backprop derivation (practice on whiteboard)
- [ ] ROC axes drill (recurring confusion ‚Äî FPR on x, TPR on y)
- [ ] SHAP practice (explain Shapley values fluently)

---

## Session History Summary

| Date | Topics Covered | Key Wins | Gaps Found |
|------|---------------|----------|------------|
| 2026-02-02 (Session 1) | A.8 AUC-ROC evaluation metric | ‚Ä¢ Understood ROC curve (corrected axis confusion)<br>‚Ä¢ Mastered AUC vs Precision@k tradeoffs<br>‚Ä¢ Can apply to real scenarios (rec sys, fraud detection)<br>‚Ä¢ Interview-ready for AUC questions | ‚Ä¢ Initially confused ROC axes (resolved)<br>‚Ä¢ Needed clarification on metric selection (resolved) |
| 2026-02-02 (Session 2) | A.3 Logistic regression gradient w/ L2 regularization | ‚Ä¢ **First use of 3-step structured workflow - success!**<br>‚Ä¢ Derived complete gradient from first principles<br>‚Ä¢ Mastered chain rule application in ML<br>‚Ä¢ Understood beautiful simplification: ‚àÇL/‚àÇz = ≈∑ - y<br>‚Ä¢ Can perform whiteboard derivation<br>‚Ä¢ Grasped weight decay intuition | ‚Ä¢ Chain rule was fuzzy (resolved with review)<br>‚Ä¢ Made errors on BCE derivative (corrected)<br>‚Ä¢ Minor: didn't cover bias gradient or batch averaging |
| 2026-02-02 (Session 3) | C.21 Transformers & self-attention mechanism | ‚Ä¢ **Student had exceptional baseline knowledge!**<br>‚Ä¢ Structured understanding into interview-ready format<br>‚Ä¢ Self-attention: Q, K, V mechanism and O(n¬≤) trade-off<br>‚Ä¢ Positional encodings: RoPE, sinusoidal, learned<br>‚Ä¢ BERT vs GPT: encoder/decoder, bidirectional/causal<br>‚Ä¢ Applied knowledge to practical scenarios<br>‚Ä¢ **3 topics mastered in one day!** | ‚Ä¢ Minor: didn't know about causal masking in GPT (added)<br>‚Ä¢ Minor: less familiar with all positional encoding types (covered) |
| 2026-02-03 (Session 4) | Multi-head attention, Backprop, Softmax+CE, ML Pipelines | ‚Ä¢ **4 major topics in one session!**<br>‚Ä¢ Strong math derivations for backprop and softmax<br>‚Ä¢ Connected concepts across sessions<br>‚Ä¢ ML System Design shows real-world experience<br>‚Ä¢ Can whiteboard multi-head attention and gradients | ‚Ä¢ Minor derivative mechanics (corrected in session)<br>‚Ä¢ Could use more system design practice |
| 2026-02-09 (Session 5) | E.36 Monitoring, C.18 Norms, F.39 Imbalance, A.8 AUC review, F.42 SHAP, F.38 Debugging | ‚Ä¢ Built 4-layer monitoring framework (interview-ready)<br>‚Ä¢ Mastered drift types and weighted CE gradient derivation<br>‚Ä¢ Learned focal loss, SHAP/Shapley values, AUC-PR<br>‚Ä¢ Systematic debugging framework (4-row table)<br>‚Ä¢ Strong cross-topic connections throughout<br>‚Ä¢ **6 topics in one session ‚Äî most productive yet!** | ‚Ä¢ ROC axes swapped again (recurring)<br>‚Ä¢ BatchNorm placement corrected<br>‚Ä¢ L1/Lasso distinction corrected<br>‚Ä¢ Sudden NaN reasoning needed guidance |
| 2026-02-10 (Session 6) | C.23 Unified SFT/Distillation/RL Framework | ‚Ä¢ Built complete 2x2 framework (on/off-policy √ó sparse/dense) Socratically<br>‚Ä¢ Derived unified gradient: weight √ó ‚àálog œÄ_Œ∏ for all four methods<br>‚Ä¢ Applied importance sampling to unify off-policy under on-policy expectation<br>‚Ä¢ Proved SFT = sparse RL with indicator reward<br>‚Ä¢ Strong practical trade-off reasoning (RL vs distillation) | ‚Ä¢ IS application: forgot œÄ_data in numerator (minor)<br>‚Ä¢ Initially confused On-Policy Distillation with RL (added reward where none exists) |
| 2026-02-10 (Session 7) | D.31 Contrastive Learning, InfoNCE, ID Embeddings, Cold Start | ‚Ä¢ InfoNCE formula & cross-entropy connection mastered<br>‚Ä¢ Temperature, batch size, projection head practical details<br>‚Ä¢ ID embedding pipeline: simple lookup vs compositional embeddings<br>‚Ä¢ Cold start: user & item sides, two-tower architecture<br>‚Ä¢ Independently identified feedback loop / popularity bias problem<br>‚Ä¢ 8 interconnected concepts in one session | ‚Ä¢ Initially wrote "InfoBCE" (typo, corrected)<br>‚Ä¢ Temperature framing: said "randomization" instead of "sharpness" (minor) |
| 2026-02-10 (Session 8) | E.34 System Design: Airbnb Relisting Detection | ‚Ä¢ First full end-to-end system design practice<br>‚Ä¢ Strong problem framing (fraud/imbalanced, precision priority)<br>‚Ä¢ Good retrieval design (geo filter + FAISS ANN)<br>‚Ä¢ Solid feature categories and model selection philosophy<br>‚Ä¢ Connected contrastive learning to practical system<br>‚Ä¢ Label flywheel and tiered action concepts | ‚Ä¢ Interview delivery: jumped to features before pipeline structure<br>‚Ä¢ Behavioral/network signals needed prompting<br>‚Ä¢ Adversarial adaptation answer too vague initially |
| 2026-02-10 (Session 9) | E.34 System Design: Listing Recommendation | ‚Ä¢ Pipeline-first delivery (big improvement over Session 8)<br>‚Ä¢ Multi-stakeholder framing (two-sided marketplace)<br>‚Ä¢ Deep ranking architecture discussion (DCN vs transformer, masking patterns)<br>‚Ä¢ Creative prefix-mask transformer proposal<br>‚Ä¢ Connected cold start/feedback loop across sessions<br>‚Ä¢ Multi-objective scoring and re-ranking business logic | ‚Ä¢ Forgot hard filters in summary<br>‚Ä¢ Missing problem framing opener and eval/monitoring closer<br>‚Ä¢ CF retrieval path and revenue-based weights needed prompting |
| 2026-02-10 (Session 10) | E.34 System Design: Family-Friendly Listings | ‚Ä¢ Best summary delivery of all 3 designs<br>‚Ä¢ Strong integration design (ff_scorer as filter + boost + feature)<br>‚Ä¢ Self-identified blind spot: metrics must segment by target audience<br>‚Ä¢ Connected AUC-PR for imbalanced from Session 5<br>‚Ä¢ Multi-modal fusion tradeoffs (separate scores vs embedding concat)<br>‚Ä¢ Image classification for family-friendly ‚Äî strong independent idea | ‚Ä¢ Label sources missing from summary<br>‚Ä¢ Initial feature answer too brief<br>‚Ä¢ "Family friendly" definition initially scattered |
| 2026-02-10 (Session 11) | A.3 Optimizers: SGD ‚Üí Momentum ‚Üí RMSProp ‚Üí Adam ‚Üí AdamW | ‚Ä¢ Built complete optimizer progression step-by-step<br>‚Ä¢ Strong momentum intuition (cancel oscillation, accumulate consistent direction)<br>‚Ä¢ Good RMSProp numerical reasoning (amplification for rare parameters)<br>‚Ä¢ Understood Adam bias correction and Œ≤‚ÇÇ > Œ≤‚ÇÅ implication<br>‚Ä¢ AdamW: decoupled weight decay concept understood | ‚Ä¢ Bias correction: couldn't derive independently<br>‚Ä¢ AdamW wording slightly imprecise<br>‚Ä¢ SGD sign error (minor) |
| 2026-02-17 (Session 12) | E.38 Cost Optimization, Quantization Math, QAT, Distillation Math | ‚Ä¢ Comprehensive cost optimization framework (compression, smart inference, infrastructure)<br>‚Ä¢ Quantization formulas derived with concrete examples<br>‚Ä¢ Symmetric vs asymmetric tradeoffs + when-to-use rules<br>‚Ä¢ PTQ vs QAT: fake quantization mechanism, STE, deployment pipeline<br>‚Ä¢ Distillation math: dark knowledge, temperature, KL divergence, T¬≤ scaling<br>‚Ä¢ Semantic caching: connected threshold to precision-recall tradeoff<br>‚Ä¢ Strong cross-session linking (temperature ‚Üî InfoNCE from Session 7)<br>‚Ä¢ **ML System Design domain complete (8/8)!** | ‚Ä¢ Missed batching in interview answer<br>‚Ä¢ Forgot STE in quantization summary<br>‚Ä¢ QAT terminology: "fade" vs "fake"<br>‚Ä¢ Distillation rehearsal incomplete |

---

*This tracker is your single source of truth for interview preparation progress.*
